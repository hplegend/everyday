[TOC]

## 深度学习及在图像目标检测中的应用



 人识别物体是根据物体的特征来进行识别、分类。而计算机要识别所看到的物体，也需要根据特征来识别。计算机识别区别于人的识别主要在于人是一直在学习，并把学习的东西记忆在大脑。因此，计算机要想识别，也必须事先学习物体的特征。 特征学习，可以说是计算机视觉的核心。目标检测，实际上也就是物体识别，只有了解了物体的特征，才能更好的检测，因此， 其核心也是特征学习。

在传统视觉领域，物体检测是一个非常热门的研究方向。受70年代落后的技术条件和有限应用场景的影响，物体检测直到上个世纪90年代才开始逐渐走入正轨。物体检测对于人眼来说并不困难，通过对图片中不同颜色、纹理、边缘模块的感知很容易定位出目标物体，但对于计算机来说，面对的是RGB像素矩阵，很难从图像中直接得到狗和猫这样的抽象概念并定位其位置，再加上物体姿态、光照和复杂背景混杂在一起，使得物体检测更加困难。

检测算法里面通常包含三个部分，第一个是检测窗口的选择， 第二个是特征的设计，第三个是分类器的设计。随着2001年Viola Jones提出基于Adaboost的人脸检测方法以来，物体检测算法经历了传统的人工设计特征+浅层分类器的框架，到基于大数据和深度神经网络的End-To-End的物体检测框架，物体检测一步步变得愈加成熟。

#### 传统的方法怎么做？有什么缺点？

传统算法大致可以分为目标实例检测与传统目标类别检测两类：

（1）目标实例检测问题通常利用模板和图像稳定的特征点，获得模板与场景中对象的对应关系，检测出目标实例。目标实例检测关注的只是具体目标本身，图像中的其余对象都是无关量。常用的算法有：SIFT算法，PCA-SIFT，SURF等，这些算法的共同点都是通过提取图像上的特征进行检测与匹配。

（2）传统目标类别检测则通过使用 AdaBoost算法框架、HOG特征和支持向量机等方法，根据选定的特征和分类器，检测出有限的几种类别。使用特征检测+分类框架做目标检测，实际上属于浅层次的智能方法，通常也分为连个阶段：训练阶段和识别应用阶段。这类方法额特征检测大多数采用计算机视觉桑的角点检测，特征直方图等。传统的目标类别检测局限性在于手工的特征选取，已经分类算法的高复杂度上，

![1547566978315](D:\hp\github\everyday\yswork\%5CUsers%5Chp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1547566978315.png)

![1547567021128](D:\hp\github\everyday\yswork\%5CUsers%5Chp%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1547567021128.png)

传统方法的缺点：

总的来说，这些算法的目的都是在保证提取丰富、准确特征的前提下，快速地进行特征计算及预测。但传统算法提取的特征基本都是低层次、人工选定的特征，这些特征相对更直观、易理解，针对特定对象更有针对性，但不能很好地表达大量、多类目标。另外，传统方法如区域检测的时间复杂度很高，且很难针对性的进行目标的搜寻。另一方面，手工设计的特征对于物体的多样性变化、复杂物体等的鲁棒性并不强，且随着检测任务的推广，设计特征变得越来越复杂。



#### 深度学习解决了传统方法的缺点？

深度学习到底解决了传统方法的哪个缺点呢？

与传统方法相比，深度学习在分类精度上提高很多。起先，深度学习只是在分类上有非常明显的提升，之后也带动了检测这一块。从物体分类到物体检测，利用了深度学习比较强的feature的表达能力，可以进一步提高检测的精度。传统的物体检测方法因为其特征比较弱，所以每类都需要训练一个检测器。每个检测器都是针对特定的物体训练，如果有20类的话，就需要跑20次前向预测，相当于单次检测的20倍，作为一个2C端产品，时间消耗和精度性能使得传统方法检测的应用场景不是很多。

总结起来：深度学习由于其特殊的网络结构，能存储更多的特征信息，在效率和精度上都有很大的提高。另外就是深度学习利用模拟人脑的自学习过程，能够自动的学习到物体的特征，并用于后续的检测或者识别。

主要有两种主流的算法：一类是结合 region proposal、CNN网络的，基于分类的 R-CNN 系列目标检测框架，也叫两阶段网络（Two Stage）；另一类 则是将目标检测转换为回归问题的算法，也叫一阶段网络（Single Stage）。 



#### 现有的方法，各有什么特点？

##### 基于分类的方法

基于分类的方法比较有代表性的工作是Ross B. Girshick与2014年提出的R-CNN，该方法首次将卷积神经网络应用在目标检测领域，并通过 Fast R-CNN、Faster R-CNN这一系列后续工作，将目标识别任务从仅用CNN做特征提取，发展成为使用CNN进行特征提取、Softmax进行分类（Fast R-CNN），最后发展为使用神经网络直接完成从区域检测、特征提取、分类的所有工作并实现了End to End的训练，因为引入用于目标检测的RPN网络相较于Selective Search算法的优异性能表现，Faster R-CNN方法基本实现了接近实时的目标检测。

我们说的基于分类的目标检测框架也叫两阶段方法，那么这两阶段体现在哪里了？ 

![1547616064571](1547616064571.png)

上面这幅图，很好的解释了两阶段的过程。第一阶段：特征提取阶段，主要是训练CNN网络进行特征学习；第二阶段：分类识别阶段，这里用CNN网络的输出作为SVM，Adboost等的输入，来实现最终的分类（识别，检测）。

两阶段方法相比于传统的方法，两阶段的方法最大改进在于用CNN网络来表达更多的特征，相比于Haar角点或者HOG特征直方图等具有更强的表达能力。当然CNN的计算过程也是穷举变量图像，因此计算时间复杂度高，效率上没有优势，当时在最终的检测识别效果上有很大的改进。

##### 基于回归的方法

之前基于分类的目标检测算法采用的方案的思路大体上可以分为两步：首先在图像上检测出许多不同尺寸的bounding box，再通过相应的分类器对bounding box内的区域进行评估，确定是否存在某类物体。

而基于回归的方法不同，该类方法把目标检测问题当作回归问题进行处理，所以不需要显式地对其进行划分和分类，而是使用网络直接对输入图像进行处理，输出检测出目标的分类、位置和置信度。基于回归的目标检测代表性方法有YOLO和基于YOLO发展出来的SSD。

YOLO将输入图像划分为SxS个网格，如果一个物体中心落在某网格内，则该网格负责检测该物体。训练和测试时，每个网格预测B个bounding boxes，其中包括该bounding box的坐标和对应分类的置信度。

YOLO模型虽然速度很快，但是存在着一些缺陷；如每个网格仅能预测一个目标，相邻目标容易产生漏检；对于物体的尺度较为敏感，对尺度变化较大的物体泛化能力差；对小目标检测效果不佳等[15]。

故SSD综合了YOLO和Faster R-CNN的anchor box思路，不再使用统一固定大小的cell，而是在不同层的feature map cell上划分出不同长宽比的default box，不同层的feature map上具有不同的感受野，这样能够有效兼顾不同尺度的目标。



#### CNN详解









#### reference

https://www.jiqizhixin.com/articles/2017-04-06

https://www.zhihu.com/question/34223049

http://www.voidcn.com/article/p-kkznyico-ue.html

http://www.voidcn.com/article/p-vllyzrme-bon.html

https://t.cj.sina.com.cn/articles/view/6552764637/1869340dd01900d15p

https://zrstea.com/264/

https://www.tinymind.cn/articles/685

https://www.cnblogs.com/houjun/p/8424893.html

https://blog.csdn.net/v_JULY_v/article/details/80170182